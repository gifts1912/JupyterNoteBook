{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "import numpy\n",
    "from random import shuffle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "queryTrain = []\n",
    "passageTrain = []\n",
    "\n",
    "def label_file(fr, qIdx, pIdx):\n",
    "    fw_q = open(\"D:/demo/queryLabel.tsv\", 'w', encoding='utf-8')\n",
    "    fw_p = open(\"D:/demo/passageLabel.tsv\", 'w', encoding='utf-8')\n",
    "    \n",
    "    with open(fr, 'r', encoding='utf-8') as fr:\n",
    "        for item_no, line in enumerate(fr):\n",
    "            arr = line.split('\\t')\n",
    "            query = arr[qIdx]\n",
    "            passage = arr[pIdx]\n",
    "            queryTrain.append(LabeledSentence(utils.to_unicode(query).split(), [\"query\" + \"_%s\"%item_no]))\n",
    "            fw_q.write(\"{0}\\t{1}\".format(\"query\" + \"_%s\"%item_no, line))\n",
    "            \n",
    "            passageTrain.append(LabeledSentence(utils.to_unicode(passage).split(), [\"passage\" + \"_%s\"%item_no]))\n",
    "            fw_p.write(\"{0}\\t{1}\".format(\"passage_%s\"%item_no, line))\n",
    "    \n",
    "    fw_q.close()\n",
    "    fw_p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelLineSentence(object):\n",
    "    def __init__(self, source):\n",
    "        self._source = source\n",
    "        \n",
    "        #make sure the labels are unique\n",
    "        flipped = {}\n",
    "        for fn, label in self._source.items():\n",
    "            if label in flipped:\n",
    "                raise Exception(\"Non-unique prefix encountered!\")\n",
    "            else:\n",
    "                flipped[label] = fn\n",
    "            \n",
    "        \n",
    "    def __iter__(self):\n",
    "        for fn, prefix in self._source.items():\n",
    "            with open(fn, 'r', encoding='utf-8') as fr:\n",
    "                for item_no, line in enumerate(fr):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + \"_%s\"%item_no])\n",
    "                    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for fn, prefix in self._source.items():\n",
    "            with open(fn, 'r', encoding='utf-8') as fr:\n",
    "                for item_no, line in enumerate(fr):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + \"_%s\"%item_no]))    \n",
    "        return self.sentences\n",
    "    \n",
    "    def setences_perm(self):\n",
    "        shuffle(self.sentences)\n",
    "        return self.sentences\n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_file(\"D:/demo/JudgeResult.tsv\", 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['activate', 'imessage', 'iphone', '6', 'plus'], tags=['query_0']),\n",
       " LabeledSentence(words=['activate', 'imessage', 'iphone', '6', 'plus'], tags=['query_1']),\n",
       " LabeledSentence(words=['water', 'conflicts'], tags=['query_2']),\n",
       " LabeledSentence(words=['installing', 'windows', '10', 'vmware'], tags=['query_3']),\n",
       " LabeledSentence(words=['installing', 'windows', '10', 'vmware'], tags=['query_4']),\n",
       " LabeledSentence(words=['season', 'corn', 'beef'], tags=['query_5']),\n",
       " LabeledSentence(words=['morosely', 'adj', 'definition'], tags=['query_6']),\n",
       " LabeledSentence(words=['morosely', 'adj', 'definition'], tags=['query_7']),\n",
       " LabeledSentence(words=['average', 'salary', 'without', 'college', 'degree'], tags=['query_8']),\n",
       " LabeledSentence(words=['federal', 'fiduciary', 'definition'], tags=['query_9'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queryTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledSentence(words=['following', 'guides', 'activate', 'iMessage', 'iPhone', '6,', 'iPhone', '6', 'Plus,', 'iPhone', '5s,', 'iPhone', '5c,', 'iPhone', '5,', 'iPhone', '4s,', 'iPhone', '4,', 'iPad', 'Air', '2,', 'iPad', 'Air,', 'iPad', 'Mini', '3,', 'iPad', 'Mini', '2,', 'iPad', 'Mini,', 'iPad', '4,', 'iPad', '3', 'iPad', '2.'], tags=['passage_0']),\n",
       " LabeledSentence(words=['following', 'guides', 'activate', 'iMessage', 'iPhone', '6,', 'iPhone', '6', 'Plus,', 'iPhone', '5s,', 'iPhone', '5c,', 'iPhone', '5,', 'iPhone', '4s,', 'iPhone', '4,', 'iPad', 'Air', '2,', 'iPad', 'Air,', 'iPad', 'Mini', '3,', 'iPad', 'Mini', '2,', 'iPad', 'Mini,', 'iPad', '4,', 'iPad', '3', 'iPad', '2.'], tags=['passage_1']),\n",
       " LabeledSentence(words=['Water', 'Conflict.', 'ongoing', 'effort', 'understand', 'connections', 'water', 'resources,', 'water', 'systems,', 'international', 'security', 'conflict,', 'Pacific', 'Institute', 'initiated', 'project', 'late', '1980s', 'track', 'categorize', 'events', 'related', 'water', 'conflict,', 'continuously', 'updated', 'since.'], tags=['passage_2']),\n",
       " LabeledSentence(words=['installed', 'Windows', '10', 'Virtual', 'Machine.', 'able', 'install', 'VMware', 'tools', 'running', 'perfectly!', 'Use', 'Machine', 'type', 'Windows', '8', '-', '64Bit,', 'provide', 'least', '2', 'processors,', '2GB', 'RAM', 'network', 'connection', 'Internet.', 'Internet', 'connection', 'required', 'signing', 'using', 'Live', 'id.'], tags=['passage_3']),\n",
       " LabeledSentence(words=['installed', 'Windows', '10', 'Virtual', 'Machine.', 'able', 'install', 'VMware', 'tools', 'running', 'perfectly!', 'Use', 'Machine', 'type', 'Windows', '8', '-', '64Bit,', 'provide', 'least', '2', 'processors,', '2GB', 'RAM', 'network', 'connection', 'Internet.', 'Internet', 'connection', 'required', 'signing', 'using', 'Live', 'id.'], tags=['passage_4']),\n",
       " LabeledSentence(words=['Ladle', 'hot', 'cooking', 'liquid', 'corned', 'beef', 'season', 'pepper.', 'Serve', 'immediately', 'mustard', 'horseradish', 'sauce.', 'small', 'bowl,', 'mix', 'together', 'mayonnaise,', 'sour', 'cream,', 'horseradish,', 'zest,', '2', 'teaspoons', 'salt.', 'Season', 'generously', 'pepper', 'taste.'], tags=['passage_5']),\n",
       " LabeledSentence(words=['LINK', '/', 'CITE', 'ADD', 'WORD', 'LIST.', 'adjective.', 'definition', 'morosely', 'something', 'done', 'bad', 'temper', 'gloomy', 'mood.', 'example', 'morosely', 'reluctantly', 'agree', 'something', 'grumpy', 'whole', 'time', 'it.'], tags=['passage_6']),\n",
       " LabeledSentence(words=['LINK', '/', 'CITE', 'ADD', 'WORD', 'LIST.', 'adjective.', 'definition', 'morosely', 'something', 'done', 'bad', 'temper', 'gloomy', 'mood.', 'example', 'morosely', 'reluctantly', 'agree', 'something', 'grumpy', 'whole', 'time', 'it.'], tags=['passage_7']),\n",
       " LabeledSentence(words=['Potential.', 'Earning', 'power', \"bachelor's\", 'degree', 'boosts', 'average', 'salary', 'significantly.', '2011,', 'BLS', 'states', 'average', 'weekly', 'income', 'worker', 'holding', \"bachelor's\", 'degree', '$1,053.', 'However,', 'median', 'income', '$45,000', 'trends', 'slightly', 'downward', '2009.'], tags=['passage_8']),\n",
       " LabeledSentence(words=['Fiduciary', 'duty', 'legal', 'requirement', 'loyalty', 'care', 'applies', 'person', 'organization', 'fiduciary', 'relationship', 'another', 'person', 'organization.'], tags=['passage_9'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passageTrain[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train = queryTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_train.extend(passageTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4388"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(passageTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, window=5, size=100, sample=1e-4, negative=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.build_vocab(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    shuffle(all_train)\n",
    "    model.train(all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t0.15508664736241742\n",
      "1\t0.17607638849604604\n",
      "2\t0.3457598302000365\n",
      "3\t0.43879796223253364\n",
      "4\t0.4299172362641229\n",
      "5\t0.3295498331421936\n",
      "6\t0.620914786211397\n",
      "7\t0.6328540594012924\n",
      "8\t0.2882902772010174\n",
      "9\t0.3240142177289195\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    score = model.docvecs.similarity(\"query_%d\"%i, \"passage_%d\"%i)\n",
    "    print(\"{0}\\t{1}\".format(i, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4388.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(int(len(all_train)/2)):\n",
    "    querylabel = \"query_%d\"%i\n",
    "    passagelabel = \"passage_%d\"%i\n",
    "    score = model.docvecs.similarity(querylabel, passagelabel)\n",
    "    scores.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr = open(\"D:/demo/JudgeResult.tsv\", 'r', encoding='utf-8')\n",
    "fw = open(\"D:/Project/Malta/QueryPassage_SimScore.tsv\", 'w+', encoding='utf-8')\n",
    "\n",
    "for item_no, line in enumerate(fr):\n",
    "    score = scores[item_no]\n",
    "    fw.write(\"{0}\\t{1}\\n\".format(line.strip(), score))\n",
    "    \n",
    "fr.close()\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8776"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"D:/Project/Malta/SemanticFeatureModuleV0_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimScore analysis between perfect and bad data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_simScore = []\n",
    "neg_simScore = []\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Schema = collections.namedtuple(\"Schema\", \"query url passage title judge simScore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"D:/Project/Malta/QueryPassage_SimScore.tsv\", 'r', encoding='utf-8') as fr:\n",
    "    for line in fr:\n",
    "        arr = line.split('\\t')\n",
    "        if(arr[4] == \"Bad\"):\n",
    "            neg_simScore.append(float(arr[5]))\n",
    "        elif(arr[4] ==\"Perfect\"):\n",
    "            pos_simScore.append(float(arr[5]))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 2950)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_simScore), len(pos_simScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1436, 1436)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffle(pos_simScore)\n",
    "pos_simScore = pos_simScore[:1436]\n",
    "len(neg_simScore), len(pos_simScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plt_gen(arr, v_num):\n",
    "    for f in arr:\n",
    "        f = str(f)\n",
    "        f = f[:f.find('.') + 2]\n",
    "        f = float(f)\n",
    "        if (f not in v_num):\n",
    "            v_num[f] = 0\n",
    "        v_num[f] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_plt_dic = {}\n",
    "pos_plt_dic = {}\n",
    "plt_gen(neg_simScore, neg_plt_dic)\n",
    "plt_gen(pos_simScore, pos_plt_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def x_y(dic, x_arr, y_arr):\n",
    "    for key, num in dic.items():\n",
    "        x_arr.append(key)\n",
    "        y_arr.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_x_arr = []\n",
    "pos_y_arr = []\n",
    "neg_x_arr = []\n",
    "neg_y_arr = []\n",
    "\n",
    "x_y(neg_plt_dic, neg_x_arr, neg_y_arr)\n",
    "x_y(pos_plt_dic, pos_x_arr, pos_y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.3, 0.5, 0.6, 0.8, -0.0, 0.7, 0.2, -0.1, 0.1, 0.4],\n",
       " [0.1, 0.3, 0.6, 0.8, 0.5, 0.7, 0.2, -0.1, 0.4, 0.0])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_x_arr,neg_x_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_series = Series(pos_y_arr, index = pos_x_arr)\n",
    "\n",
    "neg_series = Series(neg_y_arr, index = neg_x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_series = pos_series.sort_index()\n",
    "neg_series = neg_series.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1      2\n",
       " 0.0     62\n",
       " 0.1    153\n",
       " 0.2    273\n",
       " 0.3    343\n",
       " 0.4    292\n",
       " 0.5    207\n",
       " 0.6     76\n",
       " 0.7     24\n",
       " 0.8      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_neg_pd = pd.concat([pos_series, neg_series], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ab20cc6a58>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_pd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
